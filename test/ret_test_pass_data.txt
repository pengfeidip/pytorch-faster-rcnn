Scales: [128, 256, 512] Aspect ratios: [1, 0.5, 2] Roi pooling size: (7, 7)
-------------------------------------------VGG--------------------------------------------
VGGBackbone(
  (backbone): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
  )
)
-------------------------------------------RPN--------------------------------------------
RPN(
  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (classifier): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))
  (regressor): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))
)
RCNN(
  (fc1): Linear(in_features=25088, out_features=4096, bias=True)
  (fc2): Linear(in_features=4096, out_features=4096, bias=True)
  (classifier): Linear(in_features=4096, out_features=21, bias=True)
  (regressor): Linear(in_features=4096, out_features=84, bias=True)
)
-------------------------------------------RCNN-------------------------------------------
Initialized rcc with VGG fully connected layers.
Number of images to test: 1

A new image: 0
Image shape: torch.Size([1, 3, 600, 800]) BBoxes data shape: torch.Size([1, 5, 5])
BBox data: tensor([[[419, 336,  99, 206,   1],
         [262, 421, 142, 174,   1],
         [  6, 389, 101, 210,   1],
         [384, 309,  88, 170,   1],
         [442, 296,  58,  56,   1]]])
Feature map size: torch.Size([1, 512, 37, 50])
Number of anchor targets: 256
5 of anchor targets:
{anchor:{center:xy:(88.0, 397.3),feat_loc:xy:(5, 24),scale_idx:0,ar_idx:1,bbox:BBox:xywh(56.0, 269.3, 64.0, 256.0),id:3533},gt_bbox:None,gt_label:0,category:None,iou:None}
*****************************************Test RPN*****************************************
cls_out shape: torch.Size([1, 18, 37, 50])
reg_out shape: torch.Size([1, 36, 37, 50])
cls_out: tensor([ 0.0709,  0.0581,  0.0052, -0.0120, -0.0347,  0.0890,  0.1610,  0.1057,
         0.0505, -0.0033, -0.0049,  0.0094,  0.0124,  0.0057,  0.0050, -0.0025,
        -0.0056, -0.0106, -0.0026,  0.0144], grad_fn=<SliceBackward>) ...
reg_out: tensor([-0.0971, -0.0910, -0.0345, -0.0762, -0.0596, -0.0835, -0.1309, -0.1576,
        -0.1136, -0.0872, -0.0921, -0.0370, -0.0267, -0.0248, -0.0271, -0.0305,
        -0.0375, -0.0418, -0.0366, -0.0359], grad_fn=<SliceBackward>) ...
rpn loss: tensor(1.6140, grad_fn=<AddBackward0>)
Filtered proposals generated: 1306
Filtered proposals[10] {center:xy:(344.0, 348.65),feat_loc:xy:(21, 21),scale_idx:0,ar_idx:1,bbox:BBox:xywh(312.0, 220.65, 64.0, 256.0),id:3074,obj_score:0.6206178069114685,adj_bbox:BBox:xywh(308.68, 234.1, 66.14, 283.56)}
********************************Test ProposalTargetCreator********************************
number of proposal targets for training RCNN: 128
Proposal targets[20]: {center:xy:(40.0, 462.16),feat_loc:xy:(2, 28),scale_idx:0,ar_idx:1,bbox:BBox:xywh(8.0, 334.16, 64.0, 256.0),id:4224,obj_score:0.5331526398658752,adj_bbox:BBox:xywh(-1.14, 362.88, 73.71, 222.74),gt_bbox:BBox:xywh(6, 389, 101, 210),gt_label:1,category:1,iou:0.5334470123961833}
*************************************Test ROICropping*************************************
len crops: 125 len prop_targets: 125
roi_pool_res.shape: torch.Size([125, 512, 7, 7])
roi_pool_res: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0.], grad_fn=<SliceBackward>) ...
RCNN cls_out.shape: torch.Size([125, 21])
RCNN reg_out.shape: torch.Size([125, 84])
cls_out: tensor([-0.5206,  0.0798, -0.2620, -0.3472, -0.2576,  0.0962, -0.0155, -0.1021,
        -0.2598, -0.3739,  0.2570, -0.1799,  0.1933, -0.0562,  0.0592, -0.1027,
         0.0464, -0.2757,  0.1912,  0.7304], grad_fn=<SliceBackward>) ...
reg_out: tensor([-0.0701, -0.4541,  0.3536,  0.2734, -0.3936, -0.1465,  0.9036,  0.4546,
         0.0563,  0.1892, -0.4371,  0.4070, -0.0817, -0.1568, -0.4817, -0.1926,
        -0.1991, -0.2336,  0.0309,  0.0254,  0.2706,  0.4625, -0.1087, -0.2643,
        -0.1886,  0.4891, -0.0156, -0.2415, -0.2458, -0.0165,  0.1203,  0.4664,
         0.0392, -0.1224,  0.2141,  0.1798,  0.4572,  0.3698, -0.2856,  0.5004],
       grad_fn=<SliceBackward>) ...
head_loss: tensor(3.7826, grad_fn=<AddBackward0>)
